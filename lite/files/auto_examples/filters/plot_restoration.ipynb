{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-image examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import skimage` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-image/scikit-image/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport lzma\n%pip install pooch\nimport pooch\n%pip install pyodide-http\nimport pyodide_http\npyodide_http.patch_all()\n\nimport re\n\nimport skimage.data._registry\n\nnew_registry_urls = {\n    k: re.sub(\n        r'https://gitlab.com/(.+)/-/raw(.+)',\n        r'https://cdn.statically.io/gl/\\1\\2',\n        url\n    )\n    for k, url in skimage.data._registry.registry_urls.items()\n}\nskimage.data._registry.registry_urls = new_registry_urls\n    \nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Image Deconvolution\n\nIn this example, we deconvolve a noisy version of an image using Wiener\nand unsupervised Wiener algorithms. These algorithms are based on\nlinear models that can't restore sharp edge as much as non-linear\nmethods (like TV restoration) but are much faster.\n\n## Wiener filter\nThe inverse filter based on the PSF (Point Spread Function),\nthe prior regularization (penalisation of high frequency) and the\ntradeoff between the data and prior adequacy. The regularization\nparameter must be hand tuned.\n\n## Unsupervised Wiener\nThis algorithm has a self-tuned regularization parameters based on\ndata learning. This is not common and based on the following\npublication [1]_. The algorithm is based on an iterative Gibbs sampler that\ndraw alternatively samples of posterior conditional law of the image,\nthe noise power and the image frequency power.\n\n.. [1] Fran\u00e7ois Orieux, Jean-Fran\u00e7ois Giovannelli, and Thomas\n       Rodet, \"Bayesian estimation of regularization and point\n       spread function parameters for Wiener-Hunt deconvolution\",\n       J. Opt. Soc. Am. A 27, 1593-1607 (2010)\n       https://www.osapublishing.org/josaa/abstract.cfm?URI=josaa-27-7-1593\n       https://hal.archives-ouvertes.fr/hal-00674508\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage import color, data, restoration\n\nrng = np.random.default_rng()\n\nastro = color.rgb2gray(data.astronaut())\nfrom scipy.signal import convolve2d as conv2\npsf = np.ones((5, 5)) / 25\nastro = conv2(astro, psf, 'same')\nastro += 0.1 * astro.std() * rng.standard_normal(astro.shape)\n\ndeconvolved, _ = restoration.unsupervised_wiener(astro, psf)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 5),\n                       sharex=True, sharey=True)\n\nplt.gray()\n\nax[0].imshow(astro, vmin=deconvolved.min(), vmax=deconvolved.max())\nax[0].axis('off')\nax[0].set_title('Data')\n\nax[1].imshow(deconvolved)\nax[1].axis('off')\nax[1].set_title('Self tuned restoration')\n\nfig.tight_layout()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}